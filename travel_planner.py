from datetime import datetime
from pydantic import BaseModel, Field
import asyncio, json

from langchain_community.tools.tavily_search import TavilySearchResults
from app.config.settings import settings

from langgraph.graph import StateGraph, END
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser

llm = ChatOpenAI(model_name="gpt-4",temperature=0.6,openai_api_key=settings.OPENAI_API_KEY)
search = TavilySearchResults(max_results=3, tavily_api_key=settings.TAVILY_API_KEY)

class TravelState(BaseModel):
    destination: str
    start_date: str
    end_date: str
    raw_info: str | None = None
    summary: str | None = None
    schedule: str | None = None

class TravelSearchOutput(BaseModel):
    attraction: str = Field(description="æ—…éŠæ™¯é»")
    food: str = Field(description="æ—…éŠç¾é£Ÿ")
    activity: str = Field(description="æ—…éŠæ´»å‹•")
    transportation: str = Field(description="äº¤é€šæ–¹å¼")
    accommodation: str = Field(description="ä½å®¿")


def search_node(state: TravelState):
    destination = state.destination
    start_date = state.start_date
    end_date = state.end_date

    queries = {
        "æ™¯é»": f"{destination} {start_date} è‡³ {end_date} æ™¯é»æ¨è–¦ è¡Œç¨‹å®‰æ’",
        # "ç¾é£Ÿ": f"{destination} {start_date} è‡³ {end_date} åœ¨åœ°ç¾é£Ÿ é¤å»³ æ¨è–¦",
        # "æ´»å‹•": f"{destination} {start_date} è‡³ {end_date} ç¯€æ…¶ æ´»å‹• å±•è¦½ è¡¨æ¼”",
        # "äº¤é€š": f"{destination} {start_date} è‡³ {end_date} äº¤é€šæ–¹å¼ åœ°éµ å…¬è»Š ç«è»Š è·¯ç·š æŒ‡å—",
        # "ä½å®¿": f"{destination} {start_date} è‡³ {end_date} ä½å®¿æ¨è–¦"
    }

    results = []
    for topic, query in queries.items():
        res = search.run(query)
        results.append(f"ã€{topic}ã€‘\n{res[:200]}")

    state.raw_info = "\n\n".join(results)
    return state
    
def summary_node(state: TravelState):
    parser = JsonOutputParser(pydantic_object=TravelSearchOutput)
    format_instructions = parser.get_format_instructions()

    template = PromptTemplate(
        input_variables=["content"],
        template=(
            """ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ—…éŠè¦åŠƒåŠ©ç†ï¼Œè«‹é–±è®€ä»¥ä¸‹æ—…éŠè³‡è¨Šå…§å®¹ï¼š{content}
            è«‹å°‡è³‡è¨Šæ•´ç†æˆåŒ…å« æ™¯é»ã€ç¾é£Ÿã€æ´»å‹•ã€äº¤é€šã€ä½å®¿äº”å€‹æ¬„ä½çš„ JSONï¼Œç”¨ç¹é«”ä¸­æ–‡è¡¨é”ã€‚"""
            # è«‹å°‡è³‡è¨Šæ•´ç†æˆåŒ…å« æ™¯é»ã€ç¾é£Ÿå…©å€‹æ¬„ä½çš„ JSONï¼Œç”¨ç¹é«”ä¸­æ–‡è¡¨é”ã€‚
        ),
        partial_variables={"format_instructions": format_instructions}
    )

    prompt = template.format(content=state.raw_info)

    response = llm([HumanMessage(content=prompt)])
    summary = parser.parse(response.content)
    state.summary = json.dumps(summary, indent=2, ensure_ascii=False)
    return state


def arrange_schedule_node(state: TravelState):
    parser = StrOutputParser()

    example = """
=== ç¬¬ 1 å¤© (2025-10-10) ===
ğŸŒ… æ—©ä¸Š 08:00-12:00
- 09:00 æŠµé”å°åŒ—è»Šç«™
- 10:00 å‰å¾€ä¸­æ­£ç´€å¿µå ‚ï¼ˆæ·é‹æ·¡æ°´ä¿¡ç¾©ç·šï¼‰
  - åƒè§€æ™‚é–“ï¼š1.5 å°æ™‚
  - é–€ç¥¨ï¼šå…è²»
  
ğŸŒ ä¸­åˆ 12:00-14:00  
- 12:30 é¼æ³°è±ä¿¡ç¾©åº—ç”¨é¤
  - æ¨è–¦ï¼šå°ç± åŒ…ã€ç‚’é£¯
  - é ç®—ï¼š400-500 å…ƒ/äºº
  
ğŸŒ† ä¸‹åˆ 14:00-18:00
- 15:00 å°åŒ— 101 è§€æ™¯å°
  - é–€ç¥¨ï¼š600 å…ƒ
  - åœç•™æ™‚é–“ï¼š2 å°æ™‚

ğŸŒƒ æ™šä¸Š 18:00-21:00
- 18:30 å¯§å¤å¤œå¸‚æ™šé¤
  - æ¨è–¦ï¼šè±¬è‚æ¹¯ã€èšµä»”ç…
  - é ç®—ï¼š200-300 å…ƒ/äºº

ğŸ’¡ ç•¶æ—¥å°æé†’ï¼š
- æ”œå¸¶æ‚ éŠå¡æ–¹ä¾¿æ­ä¹˜æ·é‹
- å°åŒ— 101 å»ºè­°æå‰ç·šä¸Šè³¼ç¥¨
- é ä¼°èŠ±è²»ï¼š1,200-1,500 å…ƒ/äºº
"""

    template = PromptTemplate(
        input_variables=["summary", "destination", "start_date", "end_date"],
        template="""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ—…éŠè¡Œç¨‹è¦åŠƒå¸«ï¼Œè«‹æ ¹æ“šä»¥ä¸‹æ—…éŠæ‘˜è¦è³‡è¨Šï¼š{summary}
            ç‚ºæ—…å®¢å®‰æ’ä¸€å€‹è¼•é¬†åˆç†çš„æ—…éŠè¡Œç¨‹ï¼Œè€ƒæ…®ï¼š
            - æ™¯é»ä¹‹é–“çš„è·é›¢èˆ‡äº¤é€šæ™‚é–“
            - é¤å»³èˆ‡æ™¯é»çš„åœ°é»æ­é…
            - ä½å®¿çš„ check-in / check-out æ™‚é–“
            - æ¯å¤©è¡Œç¨‹3-4 å€‹ä¸»è¦æ™¯é»ï¼Œä¸è¦å¤ªç·Šæ¹Š
            - æ¨™è¨»äº¤é€šæ–¹å¼å’Œé ä¼°æ™‚é–“
            fè«‹åƒè€ƒä»¥ä¸‹è¡Œç¨‹æ ¼å¼ç¯„ä¾‹ï¼š{example}
            æ—…éŠåœ°é»ï¼š{destination}
            æ—…éŠæ—¥æœŸï¼š{start_date} è‡³ {end_date}
            è«‹ä»¥ç¹é«”ä¸­æ–‡è¼¸å‡ºå®Œæ•´è¡Œç¨‹ã€‚"""
    )

    prompt = template.format(
        summary=state.summary,
        destination=state.destination,
        start_date=state.start_date,
        end_date=state.end_date,
        example=example
    )

    response = llm([HumanMessage(content=prompt)])
    state.schedule = parser.parse(response.content)
    return state

graph = StateGraph(TravelState)

graph.add_node("search_node", search_node)
graph.add_node("summary_node", summary_node)
graph.add_node("arrange_schedule_node", arrange_schedule_node)

graph.set_entry_point("search_node")
graph.add_edge("search_node", "summary_node")
graph.add_edge("summary_node", "arrange_schedule_node")
graph.add_edge("arrange_schedule_node", END)

app = graph.compile()

if __name__ == "__main__":
    state = TravelState(
        destination="å°å—",
        start_date="2025-10-24",
        end_date="2025-10-26"
    )

    final_state_dict  = app.invoke(state)
    final_state = TravelState(**final_state_dict)
    print("âœ… æ—…éŠæ‘˜è¦ï¼š")
    print(final_state.summary)
    print("\nâœ… å»ºè­°è¡Œç¨‹ï¼š")
    print(final_state.schedule)

